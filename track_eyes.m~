%% Initialize a Video Player to Display the Results
% Create a video player object for displaying video frames.
videoPlayer  = vision.VideoPlayer('Position',...
    [100 100 [size(videoFrame, 2), size(videoFrame, 1)]+30]);

%% Track the Face
% Track the points from frame to frame, and use
% |estimateGeometricTransform| function to estimate the motion of the face.

while ~isDone(videoFileReader)
    % get the next frame
    videoFrame = step(videoFileReader);
    
    faceDetector = vision.CascadeObjectDetector();
    visiblePoints = detectMinEigenFeatures(rgb2gray(videoFrame), 'ROI', bbox(2, :));

    % Track the points. Note that some points may be lost.
    %[points, isFound] = step(pointTracker, videoFrame);
    %visiblePoints = points(isFound, :);
    %oldInliers = oldPoints(isFound, :);
    
    if size(visiblePoints, 1) >= 2 % need at least 2 points
        
        % Estimate the geometric transformation between the old points
        % and the new points and eliminate outliers
        %[xform, oldInliers, visiblePoints] = estimateGeometricTransform(...
        %    oldInliers, visiblePoints, 'similarity', 'MaxDistance', 4);
        
        % Apply the transformation to the bounding box points
        %bboxPoints = transformPointsForward(xform, bboxPoints);
                
        % Insert a bounding box around the object being tracked
        %bboxPolygon = reshape(bboxPoints', 1, []);
        %videoFrame = insertShape(videoFrame, 'Polygon', bboxPolygon, ...
        %    'LineWidth', 2);
                
        % Display tracked points
        videoFrame = insertMarker(videoFrame, visiblePoints, '+', ...
            'Color', 'white');       
        
        % Reset the points
        %oldPoints = visiblePoints;
        %setPoints(pointTracker, oldPoints);
    end
    
    % Display the annotated video frame using the video player object
    step(videoPlayer, videoFrame);
end
